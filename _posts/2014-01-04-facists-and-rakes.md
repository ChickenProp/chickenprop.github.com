---
layout: post
title: Facists and Rakes
draft: true
---
There is a common refrain along the lines of "I'm okay with people believing what they want, as long as they don't impose their beliefs on others".

From a consequentialist perspective, this is correct; someone who believes something wrong is less harmful than someone who causes others to believe something wrong. Thinking gay sex is a sin is dumb; trying to outlaw gay sex is harmful.

But from a communications perspective, it's pretty misguided.

I have difficulty writing about this in the abstract, so I'm going to be concrete. The immediate inspiration for this post was [this reddit comment](http://www.reddit.com/r/science/comments/1tgjgo/pharmacy_staff_frequently_misinform_teens_seeking/ce7pxhq):

> I have no problem with people being morally against plan B and making decisions for themselves based on the their morals. However, the morals of one person should have no effect on the health decisions of someone else. Live your life, not someone else's.

Plan B is an emergency contraceptive. I know very little about it. My understanding is that it prevents fertilization, *but* some people believe that it works after fertilization, that this makes it a form of abortion, and that this makes it immoral. I believe those people are the ones the commenter is talking about. The specific group isn't too important; we can substitute "abortion" in place of "plan B", and I think the quote still sounds like something that would get highly upvoted on reddit, and would be just as wrong.

(This can get subtle. Some people say "thing X should be banned for reason Y". Other people say "even if you don't like X, we should be able to agree that it shouldn't be banned". I'm replying to those people, but only for certain values of Y.)

But as I said in a reply, people make health decisions for other people based on their morals all the time. I'm not permitted to drink the blood of the innocent (except with their consent), even if it would make me healthier, because a certain subset of society thinks that drinking the blood of the innocent is bad (unless you have their consent) and that people who do it should be locked up.

(This subset is generally called "almost everyone".)

Of course they should: the innocent have rights, and drinking their blood (without their consent) violates those rights. But a fertilized egg does not have rights, so plan B is not like drinking the blood of the innocent.

Except that people opposed to plan B think that a fertilized egg does have rights, and that plan B violates those rights.

To someone who thinks that abortion is morally equivalent to murder, saying "even if you don't like abortion, you shouldn't try to deny it to other people" sounds like "you don't have to approve of murder, but you shouldn't try to stop other people from committing it".

So when someone who thinks abortion is murder, then tries to stop other people from getting abortions, that actually seems perfectly reasonable.




It feels like most people have a moral intuition along the lines of "you should let people do what they want, unless they're hurting other people". We follow this guideline, and we expect other people to follow it. I'll call this the permissiveness principle, that behaviour should be permitted by default.

And there's another moral intuition, the harm-minimising principle: "you should not hurt other people unless you have a good reason".

But sometimes people disagree about what counts as "hurting other people". Maybe one group of people believes that tic-tacs are sentient, and that eating them constitutes harm; and another group believes that tic-tacs are not sentient, so eating them does not hurt anyone.

What should happen here is that people try to work out exactly what it is they disagree about and why. What actually happens is that people appeal to permissiveness.

Of course, by the permissiveness principle, people should be allowed to believe what they want, because holding a belief is harmless as long as you don't act on it. So we say something like "I have no problem with people being morally opposed to eating tic-tacs, but they shouldn't impose their beliefs on the rest of us."

Except that by the harm-minimising principle, those people probably *should* impose their beliefs on the rest of us. Forbidding you to eat tic-tacs doesn't hurt you much, and it saves the tic-tacs a lot of grief.

It's not that they disagree with the permissiveness principle, they just think it doesn't apply. So appealing to the permissiveness principle isn't going to help much.

I think the problem, or at least part of it, is, depending how you look at it, either double standards or not-double-enough standards.

I apply the permissiveness principle "unless they're hurting other people", which really means "unless I think they're hurting other people". I want you to apply the permissiveness principle "unless they're hurting other people", which *still* means "unless I think they're hurting other people".

Meanwhile, you apply the permissiveness principle unless *you* think they're hurting other people; and you want me to apply it unless *you* think they're hurting other people.

So when we disagree about whether or not something is hurting other people, I think you're a facist because you're failing to apply the permissiveness principle; and you think I'm a villain because I'm failing to apply the harm-minimisation principle; or vice-versa. Neither of these things is true, of course.

It gets worse, because once I've decided that you're a facist, I think the *problem* is that you're a facist. If you would only stop being a facist, all our problems would be solved. You can go on thinking tic-tacs are sentient, you just need to stop being a facist.

But you're not a facist. The *real* problem is that you think tic-tacs are sentient. You're acting exactly as you should do if tic-tacs were sentient, but they're not. I need to stop treating you like a facist, and start trying to convince you that tic-tacs are not sentient.

And, of course, you've decided I'm a villain, which isn't true, and you've decided that that's the problem, which isn't true; the problem is that I think tic-tacs aren't sentient. You need to stop treating me like a villain, and start trying to convince me that tic-tacs are sentient.

I don't expect either of us to actually convince the other, very often. If it was that easy, someone would probably have already done it. But at least I'd like us both to acknowledge that our opponent is neither a facist nor a villain, they just believe something that isn't true.






But sometimes one group of people does not want to let another group of people from doing things that the second group thinks is not hurting anyone. The second group appeals to this moral intuition. "We're not hurting anyone; you don't have to like what we're doing, but you shouldn't try to stop us." And the second group feels morally superior, because they're following this moral intuition and the other group isn't.

Except what's probably happening here is that the first group *is* following that intuition, but disagrees about whether or not the second group is hurting anyone.

The proper resolution would be to try to work out exactly what it is we disagree about and why.


 



I think the intended message is something like "even if you disagree with me on the object level of this debate, there's a meta-level principal which says this debate is irrelevant". You don't have to like gay people, and you don't have to gay married yourself, but you do have to let gay people get gay married. You don't have to like abortion, and you don't have to get an abortion yourself, but you do have to let other people get abortions.




The speaker probably doesn't actually have a problem with people imposing their beliefs on other people. As a society, we don't lock up murderers because they believe they deserve it; we lock up murderers because *we* think that murdering people is bad, and *we* want to stop them from doing it again, and we don't really care what they think.

What the speaker actually objects to, is people imposing *incorrect* beliefs on others. Murder is bad, so it's good to make laws against murder. Gay sex is not bad, so it's bad to make laws against gay sex.

The problem is that the refrain is often dressed up like, "this is a perfectly obvious moral point, and even people who disagree with me on the object level of whether *thing* is bad should agree with me that they shouldn't try to outlaw *thing*".

This is difficult to talk about vaguely, so let's pick a specific topic: abortion. People will say things like "it's okay to think abortion is wrong, but you should let people make their own decisions". Believe what you want, but don't impose your beliefs on me.

And then they get upset when people who think abortion is wrong, don't just walk away and let the rest of us get on with our abortions in peace.

The trouble is that to someone who thinks abortion is wrong, this sounds like "it's okay to think murder is wrong, but you should let people make their own decisions".

If someone thinks abortion is wrong, it's presumably because they think abortion is morally equivalent to murder, and this means they have a moral duty to try to stop it from happening, even if the people doing it don't see a problem. Similarly, even someone who believes that black people have no moral worth, isn't allowed to keep them as slaves.

Everyone is following approximately the same decision process: if something is bad, try to stop it from happening. And sometimes this causes conflicts, because sometimes people don't agree on what is and isn't bad. So someone advocates a decision process where other people say "I think this is bad but I won't try to stop it happening".

But how do you choose between bad things that you do try to stop, and bad things that you don't try to stop? I think the speaker implicitly wants the decision to be made based on the following question: "is my belief that this is bad, actually correct?"

Obviously, that's not a helpful question to ask.
